{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f38796",
   "metadata": {},
   "source": [
    "# Batch Processing\n",
    "\n",
    "## Objectives:\n",
    "- Understand batch processing and why it is used\n",
    "- Explore batch processing in Python with `joblib` library\n",
    "- Create batch ETL pipeline to update model and dashboard\n",
    "\n",
    "## What is Batch Processing\n",
    "\n",
    "### Definition\n",
    "- Jobs that can run without end user interaction, or can be scheduled to run as resources permit\n",
    "- Used for running high-volume, repetitive data jobs\n",
    "- Batch processing works in an **automated** way based on a **scheduler**\n",
    "\n",
    "More useful introductory discussion [here](https://www.talend.com/resources/batch-processing/).\n",
    "\n",
    "#### Batch vs Stream\n",
    "\n",
    "![img](https://res.cloudinary.com/hevo/images/f_auto,q_auto/v1649315584/hevo-learn/Batch-Processing-Batch-Processing-vs-Stream-Processing/Batch-Processing-Batch-Processing-vs-Stream-Processing.png?_i=AA)\n",
    "\n",
    "(Source: https://hevodata.com/learn/batch-processing/.)\n",
    "\n",
    "Batch processing is to be contrasted with serial or *stream* processing. Stream processing is critical when you need real-time updating of data reports or analyses. But if you are processing large chunks of data, it can be better to process it in batches.\n",
    "\n",
    "### Batch size\n",
    "The batch size refers to the number of work units to be processed within one batch operation. Some examples are:\n",
    "\n",
    "- The number of lines from a file to load into a database before committing the transaction.\n",
    "- The number of messages to dequeue from a queue.\n",
    "- The number of requests to send within one payload.\n",
    "\n",
    "### Common batch processing usage\n",
    "\n",
    "- Efficient bulk database updates and automated transaction processing, as contrasted to interactive online transaction processing (OLTP) applications.\n",
    "- The extract, transform, load (ETL) step in populating data warehouses is inherently a batch process in most implementations.\n",
    "- Performing bulk operations on digital images such as resizing, conversion, watermarking, or otherwise editing a group of image files.\n",
    "- Converting computer files from one format to another. For example, a batch job may convert proprietary and legacy files to common standard formats for end-user queries and display.\n",
    "\n",
    "(Source: https://en.wikipedia.org/wiki/Batch_processing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ee73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "import sqlite3\n",
    "import time\n",
    "from joblib import Parallel, delayed, Memory\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c64c215",
   "metadata": {},
   "source": [
    "## Today's Agenda\n",
    "\n",
    "Today we will be exploring batch processing through two examples:\n",
    "\n",
    "1. Use Python's `joblib` package\n",
    "1. Create simple batch ETL pipeline to continuously update a model and deploy to dashboard.\n",
    "\n",
    "## `joblib`\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Disk Caching of Functions & Lazy Re-Evaluation\n",
    "\n",
    "Cache the results of expensive function calls for later use. Useful during pipeline development.\n",
    "\n",
    "- Parallel Computing\n",
    "\n",
    "Execute multiple operations at the same time.\n",
    "\n",
    "### Caching of Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b04404",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "# Getting the square of the number:\n",
    "def square_number(no):\n",
    "    return (no*no)\n",
    "\n",
    "# Function to compute square of a range of a number:\n",
    "def get_square_range(start_no, end_no):\n",
    "    for i in np.arange(start_no, end_no):\n",
    "        time.sleep(1)\n",
    "        result.append(square_number(i))\n",
    "    return result\n",
    "\n",
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "# Total time to compute\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPLETE: Define a location to store cache\n",
    "\n",
    "result = []\n",
    "\n",
    "# Function to compute square of a range of a number:\n",
    "def get_square_range_cached(start_no, end_no):\n",
    "    for i in np.arange(start_no, end_no):\n",
    "        time.sleep(1)\n",
    "        result.append(square_number(i))\n",
    "    return result\n",
    "\n",
    "# COMPLETE: Cash results of function\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range_cached(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "# Total time to compute\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7c22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# Getting square of 1 to 20:\n",
    "final_result = get_square_range_cached(1, 21)\n",
    "end = time.time()\n",
    "\n",
    "print('\\nThe function took {:.2f} s to compute.'.format(end - start))\n",
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0099e346",
   "metadata": {},
   "source": [
    "### Parallelizing\n",
    "\n",
    "The function below is based on the following mathematical theorem:\n",
    "\n",
    "$\\large\\frac{\\pi}{4} = 1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\frac{1}{9} - ... = lim_{n\\rightarrow\\infty}\\sum^n_{j=0}\\frac{(-1)^j}{2j+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efe7e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_function(row, order, payload):\n",
    "    \"\"\"\n",
    "    Simulate process function\n",
    "    \n",
    "    Row and payload are ignored.\n",
    "    \n",
    "    Approximate pi\n",
    "    \"\"\"\n",
    "    k, pi = 1, 0\n",
    "    for i in range(10**order):\n",
    "        if i % 2 == 0: # even\n",
    "            pi += 4 / k\n",
    "        else:  # odd \n",
    "            pi -= 4 / k \n",
    "        k += 2\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4620f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984907e",
   "metadata": {},
   "source": [
    "#### Serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03319e04",
   "metadata": {},
   "source": [
    "#### Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ba1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parallel using joblib and a progress bar using tqdm\n",
    "result = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3a1a9",
   "metadata": {},
   "source": [
    "## Batch ETL Pipeline\n",
    "\n",
    "Next we will walk through a simple example of a batch ETL pipeline that can be used to update a model and deploy it to a dashboard.\n",
    "\n",
    "### Scenario\n",
    "\n",
    "We work for a store that is interested in forecasting their future sales. They have a model that forecasts total daily sales for the upcoming month. They would like us to create a pipeline that will automatically update the model on a weekly basis and deploy the results to a dashboard.\n",
    "\n",
    "### Tasks:\n",
    "- Extract recent sales data from database\n",
    "- Transform to appropriate format for time series model\n",
    "- Load to \"Data Warehouse\"\n",
    "- Train model on most recent data and deploy forecasts to dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815402b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "batch-env",
   "language": "python",
   "name": "batch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
